{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9 - Using the GPU API\n",
    "\n",
    "**GOAL:** The goal of this exercise is to show how to use GPUs with remote functions and actors.\n",
    "\n",
    "**NOTE:** These exercises are designed to run on a machine without GPUs.\n",
    "\n",
    "See the documentation on using Ray with GPUs http://ray.readthedocs.io/en/latest/using-ray-with-gpus.html.\n",
    "\n",
    "### Concepts for this Exercise - Using Ray with GPUs\n",
    "\n",
    "We can indicate that a remote function or an actor requires some GPUs using the `num_gpus` keyword.\n",
    "\n",
    "```python\n",
    "@ray.remote(num_gpus=1)\n",
    "def f():\n",
    "    # The command ray.get_gpu_ids() returns a list of the indices\n",
    "    # of the GPUs that this task can use (e.g., [0] or [1]).\n",
    "    ray.get_gpu_ids()\n",
    "\n",
    "@ray.remote(num_gpus=2)\n",
    "class Foo(object):\n",
    "    def __init__(self):\n",
    "        # The command ray.get_gpu_ids() returns a list of the\n",
    "        # indices of the GPUs that this actor can use\n",
    "        # (e.g., [0, 1] or [3, 5]).\n",
    "        ray.get_gpu_ids()\n",
    "```\n",
    "\n",
    "Then inside of the actor constructor and methods, we can get the IDs of the GPUs allocated for that actor with `ray.get_gpu_ids()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Ray, note that we pass in `num_gpus=4`. Ray will assume this machine has 4 GPUs (even if it does not). When a task or actor requests a GPU, it will be assigned a GPU ID from the set `[0, 1, 2, 3]`. It is then the responsibility of the task or actor to make sure that it only uses that specific GPU (e.g., by setting the `CUDA_VISIBLE_DEVICES` environment variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-01-24_10-10-42_21653/logs.\n",
      "Waiting for redis server at 127.0.0.1:62086 to respond...\n",
      "Waiting for redis server at 127.0.0.1:46207 to respond...\n",
      "Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.\n",
      "Starting the Plasma object store with 20.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.23.45',\n",
       " 'redis_address': '192.168.23.45:62086',\n",
       " 'object_store_addresses': ['/tmp/ray/session_2019-01-24_10-10-42_21653/sockets/plasma_store'],\n",
       " 'raylet_socket_names': ['/tmp/ray/session_2019-01-24_10-10-42_21653/sockets/raylet'],\n",
       " 'webui_url': ''}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=4, num_gpus=2, include_webui=False, ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Change the remote function below to require one GPU.\n",
    "\n",
    "**NOTE:** This change does not make the remote function actually **use** the GPU, it simply **reserves** the GPU for use by the remote function. To actually use the GPU, the remote function would use a neural net library like TensorFlow or PyTorch after setting the `CUDA_VISIBLE_DEVICES` environment variable properly. This can be done as follows.\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in ray.get_gpu_ids()])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "def f():\n",
    "    time.sleep(0.5)\n",
    "    return ray.get_gpu_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VERIFY:** This code checks that each task was assigned one GPU and that not more than two tasks are run at the same time (because we told Ray there are only two GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucess! The test passed.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gpu_ids = ray.get([f.remote() for _ in range(3)])\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "for i in range(len(gpu_ids)):\n",
    "    assert len(gpu_ids[i]) == 1\n",
    "\n",
    "assert end_time - start_time > 1\n",
    "\n",
    "print('Sucess! The test passed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** The code below defines an actor. Make it require one GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_gpus=1)\n",
    "class Actor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_gpu_ids(self):\n",
    "        return ray.get_gpu_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VERIFY:** This code checks that the actor was assigned a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f4af86cb583a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgpu_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gpu_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sucess! The test passed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actor = Actor.remote()\n",
    "\n",
    "gpu_ids = ray.get(actor.get_gpu_ids.remote())\n",
    "\n",
    "assert len(gpu_ids) == 1\n",
    "\n",
    "print('Sucess! The test passed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
