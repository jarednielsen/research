{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP SSL Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn import datasets as sk_datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from umap import UMAP\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "import rarfile\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from CifarResnet import CifarResnet\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install rarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Cifar\n",
    "cifar_data_loc = \"../data/cifar10\"\n",
    "cifar_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomRotation(30),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "cifar_test_transform = transforms.ToTensor()\n",
    "\n",
    "if not os.path.exists(cifar_data_loc):\n",
    "    os.makedirs(cifar_data_loc)\n",
    "    \n",
    "cifar10_train = datasets.CIFAR10(cifar_data_loc, train=True, transform=cifar_transform, download=True)\n",
    "cifar10_test = datasets.CIFAR10(cifar_data_loc, train=False, transform=cifar_test_transform, download=True)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, items=None, labels=None):\n",
    "        \"\"\"Initializes the dataset\n",
    "        Args:\n",
    "            items (list of Tensor): a list of dataset items in Tensor format\n",
    "            labels (list of Tensor): a list of labels in Tensor format\n",
    "        \"\"\"\n",
    "        if items is not None:\n",
    "            self.items = items\n",
    "            self.labels = labels\n",
    "        else:\n",
    "            self.items = []\n",
    "            self.labels = []\n",
    "            \n",
    "    def __getitem__(self, i):\n",
    "        return self.items[i], self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def append(self, item, label):\n",
    "        self.items.append(item)\n",
    "        self.labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identity_embedding():\n",
    "    \"\"\"As a baseline, create an 'embedding' that just returns the item itself\n",
    "    Returns:\n",
    "        embedding (nn.Module): an identity embedding\n",
    "        embed_time (float): the time in seconds to train the embedding (0)\n",
    "    \"\"\"\n",
    "    class IdentityEmbedding(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(IdentityEmbedding, self).__init__()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            return x\n",
    "        \n",
    "    embedding = IdentityEmbedding()\n",
    "    embed_time = 0\n",
    "    \n",
    "    return embedding, embed_time\n",
    "\n",
    "def get_umap_embedding(data_unlabeled):\n",
    "    \"\"\"Trains a data embedding using UMAP\n",
    "    Args:\n",
    "        data_unlabeled (Dataset): the data used to train the embedding\n",
    "    Returns:\n",
    "        embedding (nn.Module): a trained embedding using the unlabeled samples\n",
    "            from the dataset\n",
    "        embed_time (float): the time in seconds to train the embedding\n",
    "    \"\"\"\n",
    "    num_items = len(data_unlabeled)\n",
    "    item_dim = len(data_unlabeled[0][0].view(-1))\n",
    "    \n",
    "    data_shape = data_unlabeled[0][0].size()\n",
    "    data_matrix = np.zeros((num_items, item_dim))\n",
    "    \n",
    "    for i, (item, _) in enumerate(data_unlabeled):\n",
    "        data_matrix[i, :] = item.view(-1).numpy()\n",
    "        \n",
    "    print(\"Loaded UMAP data\")\n",
    "    \n",
    "    class UMAPEmbedding():\n",
    "        def __init__(self):\n",
    "            self.umap = UMAP()\n",
    "            self.umap.fit_transform(data_matrix)\n",
    "            \n",
    "        def __call__(self, x):\n",
    "            x = x.view(1, -1).numpy()\n",
    "            return self.umap.transform(x).reshape(data_shape)\n",
    "        \n",
    "    start = time.time()\n",
    "    embedding = UMAPEmbedding()\n",
    "    embed_time = time.time() - start\n",
    "    print(\"Embedded UMAP data\")\n",
    "    \n",
    "    return embedding, embed_time\n",
    "\n",
    "\n",
    "def get_umap_cheby_embedding(data_unlabeled):\n",
    "    \"\"\"Trains a data embedding using UMAP\n",
    "    Args:\n",
    "        data_unlabeled (Dataset): the data used to train the embedding\n",
    "    Returns:\n",
    "        embedding (nn.Module): a trained embedding using the unlabeled samples\n",
    "            from the dataset\n",
    "        embed_time (float): the time in seconds to train the embedding\n",
    "    \"\"\"\n",
    "    class IdentityEmbedding(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(IdentityEmbedding, self).__init__()\n",
    "        def forward(self, x):\n",
    "            return x\n",
    "        \n",
    "    embedding = IdentityEmbedding()\n",
    "    embed_time = 0\n",
    "    \n",
    "    return embedding, embed_time\n",
    "\n",
    "def get_vae_embedding(data_unlabeled):\n",
    "    \"\"\"Trains a data embedding using UMAP\n",
    "    Args:\n",
    "        data_unlabeled (Dataset): the data used to train the embedding\n",
    "    Returns:\n",
    "        embedding (nn.Module): a trained embedding using the unlabeled samples\n",
    "            from the dataset\n",
    "        embed_time (float): the time in seconds to train the embedding\n",
    "    \"\"\"\n",
    "    class IdentityEmbedding(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(IdentityEmbedding, self).__init__()\n",
    "        def forward(self, x):\n",
    "            return x\n",
    "        \n",
    "    embedding = IdentityEmbedding()\n",
    "    embed_time = 0\n",
    "    \n",
    "    return embedding, embed_time\n",
    "\n",
    "    \n",
    "def get_pca_embedding(data_unlabeled):\n",
    "    \"\"\"Trains a data embedding using PCA\n",
    "    Args:\n",
    "        data_unlabeled (Dataset): the data used to train the embedding\n",
    "    Returns:\n",
    "        embedding (nn.Module): a trained embedding using the unlabeled samples\n",
    "            from the dataset\n",
    "        embed_time (float): the time in seconds to train the embedding\n",
    "    \"\"\"\n",
    "    num_items = len(data_unlabeled)\n",
    "    item_dim = len(data_unlabeled[0][0].view(-1))\n",
    "    print(num_items, item_dim)\n",
    "    self.break_the_code()\n",
    "    data_shape = data_unlabeled[0][0].size()\n",
    "    data_matrix = np.zeros(num_items, item_dim)\n",
    "    data_matrix = []\n",
    "    \n",
    "    for i, (item, _) in enumerate(data_unlabeled):\n",
    "        data_matrix[i, :] = item.view(-1).numpy()\n",
    "        \n",
    "    data_matrix = np.array(data_matrix)\n",
    "    \n",
    "    class PCAEmbedding():\n",
    "        def __init__(self):\n",
    "            self.pca = PCA(whiten=True)\n",
    "            self.pca.fit_transform(data_matrix)\n",
    "            \n",
    "        def __call__(self, x):\n",
    "            x = x.view(1, -1).numpy()\n",
    "            return self.pca.transform(x).reshape(data_shape)\n",
    "        \n",
    "    start = time.time()\n",
    "    embedding = PCAEmbedding()\n",
    "    embed_time = time.time() - start\n",
    "    \n",
    "    return embedding, embed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_data(train, labeled=.1):\n",
    "    \"\"\"Splits the train data into labeled/unlabeled\"\"\"\n",
    "    \n",
    "    n_points = len(train)\n",
    "    labeled_split = int(n_points * labeled)\n",
    "    unlabeled_split = n_points - labeled_split\n",
    "    labeled_data, unlabeled_data = random_split(train, [labeled_split, unlabeled_split])\n",
    "    \n",
    "    return labeled_data, unlabeled_data\n",
    "\n",
    "\n",
    "def get_embeddings(embedding_names, unlabeled_data):\n",
    "    \"\"\"Trains embeddings and records how long each embedding took\n",
    "    Args:\n",
    "        embedding_names (list of str): a list of names of embedding techniques\n",
    "        unlabeled_data (Dataset): a Dataset object holding the unlabeled data\n",
    "    Returns:\n",
    "        embeddings (list of nn.Module): a list of the embeddings\n",
    "        embed_times (list of float): a list of corresponding times for training \n",
    "            the embeddings\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    embed_times = []\n",
    "    \n",
    "    for name in embedding_names:\n",
    "        if name == 'umap':\n",
    "            embedding, embed_time = get_umap_embedding(unlabeled_data)\n",
    "            embeddings.append(embedding); embed_times.append(embed_time)\n",
    "        elif name == 'tsne':\n",
    "            embedding, embed_time = get_tsne_embedding(unlabeled_data)\n",
    "            embeddings.append(embedding); embed_times.append(embed_time)\n",
    "        elif name == 'pca':\n",
    "            embedding, embed_time = get_pca_embedding(unlabeled_data)\n",
    "            embeddings.append(embedding); embed_times.append(embed_time)\n",
    "        elif name == 'umap-cheby':\n",
    "            embedding, embed_time = get_umap_cheby_embedding(unlabeled_data)\n",
    "            embeddings.append(embedding); embed_times.append(embed_time)\n",
    "        elif name == 'vae':\n",
    "            embedding, embed_time = get_vae_embedding(unlabeled_data)\n",
    "            embeddings.append(embedding); embed_times.append(embed_time)\n",
    "        elif name == 'none':\n",
    "            # Get an identity embedding as a baseline\n",
    "            embedding, embed_time = get_identity_embedding()\n",
    "            embeddings.append(embedding); embed_times.append(embed_time)\n",
    "        else:\n",
    "            raise NameError(f\"{name} is not a valid embedding\")\n",
    "            \n",
    "    return embeddings, embed_times\n",
    "\n",
    "def embed_data(embeddings, data):\n",
    "    \"\"\"Embeds the data with learned embeddings\n",
    "    Args:\n",
    "        embeddings (list of nn.Module): a list of learned embeddings\n",
    "        labeled_data (Dataset): the dataset we will train on\n",
    "    Returns:\n",
    "        data_embedded (list of Dataset): a list of Dataset objects with the\n",
    "            embedding and the original label\n",
    "    \"\"\"\n",
    "    data_embedded = []\n",
    "    \n",
    "    dataloader = DataLoader(data, \n",
    "                                shuffle=False,\n",
    "                                batch_size=1,\n",
    "                                pin_memory=True)\n",
    "    \n",
    "    for embedding in embeddings:\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        new_dataset = CustomDataset()\n",
    "        \n",
    "        for item, label in dataloader:\n",
    "            \n",
    "            item_embedded = embedding(item).detach()\n",
    "            new_dataset.append(item_embedded, label)\n",
    "            \n",
    "            i += 1\n",
    "            if i == 10:\n",
    "                break\n",
    "            \n",
    "        data_embedded.append(new_dataset)\n",
    "        \n",
    "    return data_embedded\n",
    "\n",
    "def get_algorithms(algorithm_names, output_dim):\n",
    "    \"\"\"Gets a list of specified algorithms\n",
    "    Args:\n",
    "        algorithms (list of str): a list of names of algorithms\n",
    "        unlabeled_data (Dataset): a Dataset object holding the unlabeled data\n",
    "    Returns:\n",
    "        algorithms (list of algorithms): a list of the algorithms\n",
    "    \"\"\"\n",
    "    \n",
    "    algorithms = []\n",
    "    \n",
    "    for algorithm in algorithm_names:\n",
    "        if algorithm == 'pi-model':\n",
    "            algorithms.append(PiModel(output_dim))\n",
    "        elif algorithm == 'self-training':\n",
    "            algorithms.append(SelfTraining(output_dim))\n",
    "        elif algorithm == 'cluster-label':\n",
    "            algorithms.append(ClusterLabel(output_dim))\n",
    "        elif algorithm == 'label-propagation':\n",
    "            algorithms.append(LabelPropagation(output_dim))\n",
    "        if algorithm == 'supervised':\n",
    "            algorithms.append(SupervisedAlgorithm(output_dim, pretrained=False))\n",
    "        elif algorithm == 'supervised-pretrained':\n",
    "            algorithms.append(SupervisedAlgorithm(output_dim, pretrained=True))\n",
    "        else:\n",
    "            assert False, \"Algorithm not found in list, {}\".format(algorithm)\n",
    "    return algorithms\n",
    "\n",
    "def pickle_results(results_dir, avg_acc, avg_embed_time, algorithms, embeddings):\n",
    "    \"\"\"Save the accuracy and embedding time results as pickle files, as well as\n",
    "    the algorithms and embeddings tested.\n",
    "    Args:\n",
    "        results_dir (str): the directory to save the results in\n",
    "        avg_acc ((m, n) ndarray): the accuracies for each of the m algorithms\n",
    "            with the n embeddings\n",
    "        avg_embed_time ((n,) ndarray): the time to learn the embedding for each\n",
    "            of the n embeddings\n",
    "        algorithms (list of str): the algorithms tested\n",
    "        embeddings (list of str): the embeddings tested\n",
    "    \"\"\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    pickle.dump( avg_acc, open( os.path.join(results_dir, \"avg_acc_grid.p\"), \"wb\" ) )\n",
    "    pickle.dump( avg_embed_time, open( os.path.join(results_dir, \"avg_embed_times.p\"), \"wb\" ) )\n",
    "    pickle.dump( algorithms, open( os.path.join(results_dir, \"algorithms.p\"), \"wb\" ) )\n",
    "    pickle.dump( embeddings, open( os.path.join(results_dir, \"embeddings.p\"), \"wb\" ) )\n",
    "    \n",
    "def display_results(results_dir):\n",
    "    \"\"\"Load and display the accuracy and embedding time results\n",
    "    Args:\n",
    "        results_dir (str): the directory holding the results\n",
    "    \"\"\"\n",
    "    avg_acc = pickle.load( open( os.path.join(results_dir, \"avg_acc_grid.p\"), \"rb\" ) )\n",
    "    avg_embed_time = pickle.load( open( os.path.join(results_dir, \"avg_embed_times.p\"), \"rb\" ) )\n",
    "    algorithms = pickle.load( open( os.path.join(results_dir, \"algorithms.p\"), \"rb\" ) )\n",
    "    embeddings = pickle.load( open( os.path.join(results_dir, \"embeddings.p\"), \"rb\" ) )\n",
    "    \n",
    "    print(\"Accuracies\")\n",
    "    print(tabulate(avg_acc, headers=embeddings, showindex=algorithms))\n",
    "    print(\"Embedding Times\")\n",
    "    print(tabulate(avg_embed_time, headers=embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Here\n",
      "embedding time:  89.50514793395996\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (3,32,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dc55270222a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# We possibly don't want nn.modules - we don't want to backprop on them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# fix picking k. For some rea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtest_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-dc55270222a6>\u001b[0m in \u001b[0;36mtest_embedding\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding time: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# We possibly don't want nn.modules - we don't want to backprop on them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# fix picking k. For some rea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7811dafe5edb>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (3,32,32)"
     ]
    }
   ],
   "source": [
    "def test_embedding():\n",
    "    train_data = cifar10_train\n",
    "    test_data = cifar10_test\n",
    "    output_dim = 10\n",
    "    # Proportion of labeled data\n",
    "    labeled_pct = 0.1\n",
    "    num_trials = 10\n",
    "    epochs = 1\n",
    "    results_dir = './results/basic_test'\n",
    "    \n",
    "    algorithm_names = ['supervised']\n",
    "    \n",
    "    embedding_names = ['umap']\n",
    "    \n",
    "    accuracies = []\n",
    "    embed_times = []\n",
    "\n",
    "        \n",
    "    # Note that we select a new labeled/unlabeled split with each trial\n",
    "    labeled_data, unlabeled_data = split_training_data(train_data, labeled_pct)\n",
    "\n",
    "    embeddings, embed_times = get_embeddings(embedding_names, unlabeled_data)\n",
    "    print(\"embedding time: \", embed_times[0])\n",
    "    embedding = embeddings[0]\n",
    "    print(embedding(train_data[0][0]).shape)\n",
    "    # We possibly don't want nn.modules - we don't want to backprop on them\n",
    "    # fix picking k. For some rea\n",
    "test_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Here\n",
      "Trial: 0, Embeddings Obtained\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2 into shape (3,32,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-befb0b3e3d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mdisplay_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-befb0b3e3d83>\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Trial: {trial}, Embeddings Obtained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0membedded_train_labeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0membedded_train_unlabeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munlabeled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0membedded_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e17e2a533916>\u001b[0m in \u001b[0;36membed_data\u001b[0;34m(embeddings, data)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mitem_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7811dafe5edb>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (3,32,32)"
     ]
    }
   ],
   "source": [
    "def run_experiments():\n",
    "    train_data = cifar10_train\n",
    "    test_data = cifar10_test\n",
    "    output_dim = 10\n",
    "    # Proportion of labeled data\n",
    "    labeled_pct = 0.1\n",
    "    num_trials = 10\n",
    "    epochs = 1\n",
    "    results_dir = './results/basic_test'\n",
    "    \n",
    "#     algorithm_names = ['pi-model', 'self-training', 'cluster-label', \n",
    "#                   'label-propagation', 'supervised', 'supervised-pretrained']\n",
    "#     embedding_names = ['umap', 'tsne', 'pca', 'umap-cheby', 'vae', 'none']\n",
    "    algorithm_names = ['supervised']\n",
    "    embedding_names = ['umap']\n",
    "    \n",
    "    accuracies = []\n",
    "    embed_times = []\n",
    "\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        \n",
    "        # Note that we select a new labeled/unlabeled split with each trial\n",
    "        labeled_data, unlabeled_data = split_(train_data, labeled_pct)\n",
    "        \n",
    "        embeddings, trial_embed_times = get_embeddings(embedding_names, unlabeled_data)\n",
    "        embed_times.append(trial_embed_times)\n",
    "        print(f\"Trial: {trial}, Embeddings Obtained\")\n",
    "        \n",
    "        embedded_train_labeled = embed_data(embeddings, labeled_data)\n",
    "        embedded_train_unlabeled = embed_data(embeddings, unlabeled_data)\n",
    "        embedded_test_data = embed_data(embeddings, test_data)\n",
    "        print(f\"Trial: {trial}, Data Embedded\")\n",
    "        \n",
    "        algorithms = get_algorithms(algorithm_names, output_dim)\n",
    "        print(f\"Trial: {trial}, Algorithms Obtained\")\n",
    "        \n",
    "        # trial_accuracies is a list of list. trial_accuracies[i][j] denotes the \n",
    "        # accuracy of the ith algorithm on the jth embedding\n",
    "        trial_accuracies = np.zeros((len(algorithms), len(embeddings)))\n",
    "        \n",
    "        for i, algorithm in enumerate(algorithms):\n",
    "                        \n",
    "            for j, embedding in enumerate(embeddings):\n",
    "                \n",
    "                loop = tqdm(total=epochs, position=0)\n",
    "                loop.set_description(f\"Trial: {trial} | Algorithm: {algorithm_names[i]} | Embedding: {embedding_names[j]}.\")\n",
    "                algorithm.reset()\n",
    "                accuracy = algorithm.train(embedded_train_labeled[j], \n",
    "                                           embedded_train_unlabeled[j],\n",
    "                                           embedded_test_data[j],\n",
    "                                           epochs,\n",
    "                                           loop)\n",
    "                trial_accuracies[i][j] = accuracy\n",
    "                \n",
    "        accuracies.append(trial_accuracies)\n",
    "        \n",
    "    avg_acc = np.average(np.dstack(accuracies), axis=2)\n",
    "    avg_embed_time = np.average(np.array(embed_times), axis=0).reshape(1, -1)\n",
    "    \n",
    "    pickle_results(results_dir, avg_acc, avg_embed_time, algorithm_names, embedding_names)\n",
    "    display_results(results_dir)\n",
    "    \n",
    "run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
