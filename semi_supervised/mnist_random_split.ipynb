{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Learning of MNIST CNN\n",
    "Jared Nielsen\n",
    "\n",
    "### Steps to Semi-Supervised Metrics\n",
    "- Separate MNIST into `dataset_A` and `dataset_B`. Hide the labels from `dataset_B`.\n",
    "- Instantiate `model_A` and `model_B` of the same architecture.  \n",
    "- Train `model_A` on `dataset_A`. Use `model_A` to predict the labels for `dataset_B`. \n",
    "- Train `model_B` on `dataset_B_augmented`. Use `model_B` to predict the labels for `dataset_A`.\n",
    "\n",
    "### Issues\n",
    "- If a CNN gets 98% test performance on MNIST, then it will get at worst 0.98^2 = 96% performance on transfer learning.\n",
    "\n",
    "### Comparable Architectures\n",
    "- MLP vs CNN?\n",
    "\n",
    "### Ideas\n",
    "- Should I use `mag` to serialize the models? **Yes.**\n",
    "- Fashion-MNIST instead of MNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from time import sleep\n",
    "\n",
    "import mnist_cnn\n",
    "from mnist_cnn import Net, model_A_path, model_B_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `dataset_A` and `dataset_B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"../data/\"\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root_dir, train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "n_digits = len(mnist_train)\n",
    "dataset_A, dataset_B = random_split(mnist_train, [n_digits // 2, n_digits - n_digits // 2])\n",
    "loader_A, loader_B = [DataLoader(dataset, batch_size=batch_size_train, shuffle=True) \n",
    "                      for dataset in (dataset_A, dataset_B)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train `model_A` on `dataset_A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d4ead19534482abbf16d4400eb12fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 0', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3526, Accuracy: 26890/30000 (89.63%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd60c3e7c5ac426287d0dd988a46aef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 1', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1900, Accuracy: 28323/30000 (94.41%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d976ce5b7f4648398b761e3669a395e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 2', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1422, Accuracy: 28789/30000 (95.96%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d76d1b77614f2bb2c7830b807012a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 3', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1201, Accuracy: 28900/30000 (96.33%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f102becff8d458a9672bcb8c008afd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 4', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1064, Accuracy: 29037/30000 (96.79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_A = Net()\n",
    "opt_A = optim.SGD(model_A.parameters(), lr=learning_rate,\n",
    "                 momentum=momentum)\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "def train(model_A, optimizer_A, epoch, train_loader):\n",
    "    model_A.train()\n",
    "    for batch_idx, (data, target) in tqdm_notebook(enumerate(train_loader), desc='epoch {}'.format(epoch),\n",
    "                                                  total=len(train_loader)):\n",
    "        optimizer_A.zero_grad()\n",
    "        output = model_A(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer_A.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            torch.save(model_A.state_dict(), model_A_path)\n",
    "            \n",
    "def test(network, test_loader):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        acc = 100 * correct.item() / len(test_loader.dataset)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset), acc))\n",
    "        \n",
    "for i_epoch in range(n_epochs):\n",
    "    train(model_A=model_A, optimizer_A=opt_A, epoch=i_epoch,\n",
    "          train_loader=loader_A)\n",
    "    test(network=model_A, test_loader=loader_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `model_A` with trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = Net()\n",
    "model_A.load_state_dict(torch.load(model_A_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `model_A` to label `dataset_B`, Train `model_B` on `dataset_B_hat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6acd969e594cef9f7a94a09d749218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 0', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.3422, Accuracy: 26984/30000 (89.95%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b3f25724b8494e935c33e0e7ebcb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 1', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.2328, Accuracy: 27898/30000 (92.99%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6718cc915adc4e2c8db18e306abd70ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 2', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1952, Accuracy: 28244/30000 (94.15%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14891a0810b3416bab88eb59ec8a64d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 3', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1679, Accuracy: 28494/30000 (94.98%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a010109545b4e849d176e29596cccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch 4', max=469, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test set: Avg. loss: 0.1628, Accuracy: 28588/30000 (95.29%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_B = Net()\n",
    "opt_B = optim.SGD(model_B.parameters(), lr=learning_rate,\n",
    "                 momentum=momentum)\n",
    "\n",
    "n_epochs = 5\n",
    "\n",
    "def train_with_transfer_labels(model_A, model_B, optimizer_B, epoch, train_loader):\n",
    "    model_A.eval()\n",
    "    model_B.train()\n",
    "    for batch_idx, (data, target) in tqdm_notebook(enumerate(train_loader), desc='epoch {}'.format(epoch),\n",
    "                                                  total=len(train_loader)):\n",
    "        target_hat = model_A(data)\n",
    "        target_hat = torch.argmax(target_hat, dim=1)\n",
    "        optimizer_B.zero_grad()\n",
    "        output = model_B(data)\n",
    "        loss_hat = F.nll_loss(output, target_hat)\n",
    "        loss_hat.backward()\n",
    "        optimizer_B.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            torch.save(model_B.state_dict(), model_B_path)\n",
    "        \n",
    "for i_epoch in range(n_epochs):\n",
    "    train_with_transfer_labels(model_A=model_A, model_B=model_B, optimizer_B=opt_B,\n",
    "                              epoch=i_epoch, train_loader=loader_B)\n",
    "    test(network=model_B, test_loader=loader_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
